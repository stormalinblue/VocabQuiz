{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f805d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdc4598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "connection = sqlite3.connect(\"file:db/words.db?mode=ro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6dc35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = 'stormalinblue'\n",
    "user_id = connection.execute('select id from users where users.user_name = ?', (username,)).fetchone()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14c2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.game.model as gamemodel\n",
    "from lib.common.util import utc_now_sec_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087912c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62615fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_correct = 0.25\n",
    "prior_incorrect = 0.75\n",
    "prior_total = prior_correct + prior_incorrect\n",
    "\n",
    "word_weight_table = gamemodel.word_weight_table(\n",
    "    connection,\n",
    "    user_id,\n",
    "    utc_now_sec_timestamp(),\n",
    "    prior_correct=prior_correct,\n",
    "    prior_incorrect=prior_incorrect)\n",
    "word_pos_definitions = pd.read_sql(\n",
    "    '''\n",
    "select\n",
    "    word_pos.id as word_pos_id, words.word as word, parts_of_speech.name as pos\n",
    "from\n",
    "    word_parts_of_speech as word_pos\n",
    "    join words on words.id = word_pos.word_id\n",
    "    join parts_of_speech on parts_of_speech.id == word_pos.part_of_speech_id\n",
    "order by words.word, parts_of_speech.name''',\n",
    "    con=connection,\n",
    "    index_col=['word_pos_id']\n",
    ")\n",
    "\n",
    "word_table = pd.concat([word_pos_definitions, word_weight_table], axis=1)\n",
    "print('num word pos', word_table.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8b072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "x_axis = np.linspace(0, 1, 100)\n",
    "\n",
    "n_highest = 10\n",
    "word_table['mean_prob'] = (word_table['correct']) / (word_table['correct'] + word_table['incorrect'])\n",
    "highest = word_table.sort_values('mean_prob', ascending=False).head(n_highest)\n",
    "print(highest)\n",
    "for word_pos_id, row in highest.iterrows():\n",
    "    ax.plot(x_axis, scipy.stats.beta(row.correct, row.incorrect).cdf(x_axis), label=f'{row.word} ({row.pos})')\n",
    "\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend()\n",
    "ax.set_title(f'PDFs for beta distributions for the top {n_highest} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b1a51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "n_lowest = 10\n",
    "lowest = word_table.sort_values('mean_prob', ascending=True).head(n_lowest)\n",
    "print(lowest)\n",
    "ax.plot(x_axis, scipy.stats.beta(prior_correct, prior_incorrect).cdf(x_axis), label=f'Beta({prior_correct}, {prior_incorrect})')\n",
    "for word_pos_id, row in lowest.iterrows():\n",
    "    ax.plot(x_axis, scipy.stats.beta(row.correct, row.incorrect).cdf(x_axis), label=f'{row.word} ({row.pos})')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title(f'PDFs for beta distributions for the bottom {n_lowest} words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ee69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_xlabel('Incorrect')\n",
    "ax.set_ylabel('Correct')\n",
    "ax.set_title(\"Distribution of 'correct' and 'incorrect' weights for all words\")\n",
    "ax.grid(True)\n",
    "\n",
    "mappable = ax.hist2d(word_table['incorrect'], word_table['correct'])\n",
    "fig.colorbar(mappable[3], ax=ax)\n",
    "ax.set_aspect(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(word_table['correct'] + word_table['incorrect'], range=(0, 30), bins=60)\n",
    "ax.set_title('Histogram of weights caused by user over word-pos\\'s')\n",
    "ax.set_xlabel('Weights')\n",
    "ax.set_ylabel('Num words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6797ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.hist(word_table['mean_prob'], range=(0, 1), bins=20)\n",
    "ax.set_title('Distribution of mean probabilities')\n",
    "ax.set_xlabel('Mean probability of correctness')\n",
    "ax.set_ylabel('Number of words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e3dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_incorrect = (word_table['incorrect']).sum() / word_table.shape[0]\n",
    "overall_correct = (word_table['correct']).sum() / word_table.shape[0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x_axis = np.linspace(0, 1, 1000)\n",
    "overall_distribution = scipy.stats.beta(overall_correct, overall_incorrect)\n",
    "ax.plot(x_axis, overall_distribution.cdf(x_axis))\n",
    "\n",
    "median_prob = overall_distribution.median()\n",
    "ax.axvline(median_prob, linestyle='--')\n",
    "ax.annotate(\n",
    "    text=f'$m$ = {median_prob:.02f}',\n",
    "    xy=(median_prob, 0.9),\n",
    "    xycoords=('data', 'axes fraction'),\n",
    "    xytext=(10, 0),\n",
    "    textcoords=('offset points'))\n",
    "mean_prob = overall_distribution.mean()\n",
    "ax.axvline(mean_prob, linestyle='--')\n",
    "percentile_25 = overall_distribution.ppf(0.25)\n",
    "ax.axvline(percentile_25, linestyle='--')\n",
    "ax.annotate(\n",
    "    text=f'$\\\\mu$ = {mean_prob:.02f}',\n",
    "    xy=(mean_prob, 0.9),\n",
    "    xycoords=('data', 'axes fraction'),\n",
    "    ha='right',\n",
    "    xytext=(-10, 0),\n",
    "    textcoords=('offset points'))\n",
    "percentiles = [0.05, 0.25, 0.5, 0.75, 0.95]\n",
    "for percentile in percentiles:\n",
    "    pctile_value = overall_distribution.ppf(percentile)\n",
    "    ax.axvline(pctile_value)\n",
    "ax.annotate(\n",
    "    text=f'$\\\\alpha$ = {overall_correct:.02f}, $\\\\beta$ = {overall_incorrect:.02f}',\n",
    "    xy=(0, 0.9),\n",
    "    xycoords=('data', 'axes fraction'))\n",
    "print(overall_distribution.ppf(0.05), overall_distribution.ppf(0.25), overall_distribution.ppf(0.5), overall_distribution.ppf(0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59616756",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
